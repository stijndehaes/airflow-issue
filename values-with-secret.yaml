
airflow:
  variables: '{ "environment": "dev" }'
  fernetKey: "FFZ0QjXwx7Cam0iAKK4C3z19ip3henvOx9gp8j2IB60="
  connections:
  - id: kubernetes-spark
    type: spark
    host: k8s://https://kubernetes.default
    extra: '{ "deploy-mode": "cluster", "namespace": "default" }'
  config:
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: "${local.airflow_postgres_conn_str}"
    AIRFLOW__CORE__LOGGING_LEVEL: DEBUG
    AIRFLOW__CORE__EXECUTOR: KubernetesExecutor
    AIRFLOW__KUBERNETES__DAGS_IN_IMAGE: "true"
    AIRFLOW__KUBERNETES__WORKER_CONTAINER_REPOSITORY: airflow
    AIRFLOW__KUBERNETES__WORKER_CONTAINER_TAG: 1.10.2
    AIRFLOW__KUBERNETES__NAMESPACE: airflow-secret
    AIRFLOW__KUBERNETES_SECRETS__FERNET_KEY: airflow-fernet-key=fernet-key
    AIRFLOW__KUBERNETES__DELETE_WORKER_PODS: "false"
  image:
    repository: airflow
    tag: 1.10.2
workers:
  enabled: false
serviceAccount:
  create: true
redis:
  enabled: false
